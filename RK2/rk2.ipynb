{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "rk2.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IQecT74MaE_",
        "colab_type": "text"
      },
      "source": [
        "# Рубежный контроль №2\n",
        "Демьянчук Григорий Валентинович ИУ5-22М Вариант 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvolWVa0MaFF",
        "colab_type": "text"
      },
      "source": [
        "## Задание\n",
        "Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета. Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста.\n",
        "\n",
        "Необходимо сформировать признаки на основе `CountVectorizer` или `TfidfVectorizer`.\n",
        "\n",
        "В качестве классификаторов необходимо использовать один из классификаторов, не относящихся к наивным Байесовским методам (например, `LogisticRegression`), а также Multinomial Naive Bayes (MNB), Complement Naive Bayes (CNB), Bernoulli Naive Bayes.\n",
        "Для каждого метода необходимо оценить качество классификации с помощью хотя бы одной метрики качества классификации (например, `accuracy`).\n",
        "\n",
        "Сделайте выводы о том, какой классификатор осуществляет более качественную классификацию на Вашем наборе данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhds1kk-MaFI",
        "colab_type": "text"
      },
      "source": [
        "## Решение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpAQz0KrMaFM",
        "colab_type": "text"
      },
      "source": [
        "### Загрузка и предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euvQa9-lMaFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wrSpj-oMaFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rcv_train = fetch_rcv1(subset='train')\n",
        "#rcv_test = fetch_rcv1(subset='test')\n",
        "df = pd.read_csv('/content/datasets_2050_3494_SPAM text message 20170820 - Data (1).csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sXaua6nMaF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "994c60f6-2543-4bac-deef-3d50cefaa2f9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuLxhBpwMaGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "message = np.array(df['Message'])\n",
        "category = np.array(df['Category'])\n",
        "# build train and test datasets\n",
        "\n",
        "# Train/test splitting for 41 categories of news\n",
        "from sklearn.model_selection import train_test_split    \n",
        "message_train, message_test, category_train, category_test = train_test_split(message, category, test_size=0.2, random_state=41)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sheWKGsRMaGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "## Build Bag-Of-Words on train phrases\n",
        "cv = CountVectorizer(stop_words='english',max_features=10000)\n",
        "cv_train_features = cv.fit_transform(message_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld8ZICkaMaGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build TFIDF features on train reviews\n",
        "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
        "                     sublinear_tf=True)\n",
        "tv_train_features = tv.fit_transform(message_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSynCtLzMaHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_test_features = cv.transform(message_test)\n",
        "tv_test_features = tv.transform(message_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4K2HY1MaHR",
        "colab_type": "text"
      },
      "source": [
        "### Обучение моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnIyCRMCMaHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQto33OaMaHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "def accuracy(classifier, \n",
        "                        train_features, train_labels, \n",
        "                        test_features, test_labels):\n",
        "    classifier.fit(train_features, train_labels)\n",
        "    print('Accuracy:', metrics.accuracy_score(test_labels, classifier.predict(test_features)))    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu--95VxMaHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6XVhhvRMaH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0eaf5d07-958b-4ea7-8189-a5c0813b6420"
      },
      "source": [
        "lr = LogisticRegression(solver='lbfgs',penalty='l2', max_iter=100, C=1,multi_class='auto')\n",
        "\n",
        "lr_accuracy = accuracy(classifier=lr,train_features=cv_train_features, train_labels=category_train,\n",
        "                       test_features=cv_test_features, test_labels=category_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9721973094170404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt49SWBBMaIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d8aeb18-33c9-48fe-9fbc-0108c5bfc28d"
      },
      "source": [
        "mu = MultinomialNB()\n",
        "\n",
        "mu_accuracy = accuracy(classifier=mu,train_features=cv_train_features, train_labels=category_train,\n",
        "                       test_features=cv_test_features, test_labels=category_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9838565022421525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3WlS5quMaIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e301cd3-3939-4c66-acac-11e3b64f5651"
      },
      "source": [
        "co = ComplementNB()\n",
        "\n",
        "co_accuracy = accuracy(classifier=co,train_features=cv_train_features, train_labels=category_train,\n",
        "                       test_features=cv_test_features, test_labels=category_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9766816143497757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odN1J18AMaIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a39a0a3c-e8b1-496a-94ac-9cc024d1c1ae"
      },
      "source": [
        "be = BernoulliNB()\n",
        "\n",
        "be_accuracy = accuracy(classifier=be,train_features=cv_train_features, train_labels=category_train,\n",
        "                       test_features=cv_test_features, test_labels=category_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.967713004484305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RkB82ofMaI3",
        "colab_type": "text"
      },
      "source": [
        "### Вывод\n",
        "Метод Multinomial Naive Bayes (MNB), лучше всего решает поставленную задачу бинарной классификации. "
      ]
    }
  ]
}